Our model peer review system is primarily focused on three aspects:

1. Does the model run?
2. Is it sufficiently documented? This is an admittedly subjective evaluation but you should be looking for complete
narrative documentation, either following the spirit of the ODD protocol or equivalent, that informs a reader at a high
level of the essential internals and assumptions made in the model.
3. Does the model have well-structured "clean" code with appropriate comments and documented inputs and expected outputs?

We do not expect an assessment of whether or not the model code is sound theoretically or producing correct outputs,
though if you spot any red flags in the code please feel free to point them out.


